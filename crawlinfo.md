# Crawl Info
This file contains info about each crawl.
----------------------------------------
## webcrawl-8-4-2017 (Latest) Info
This crawl obeys robots.txt.

-------------------------------------
URL filter:
No urls containing the following were crawled:

webhp

ServiceLogin

mediawiki

twitter

apple

tango

commons

File:

Wikipedia:

'#'

'?'

icann

-------------------------------------

Reason the crawl ended: Crawler memory full (This is good, as it means the maximum number of websites were crawled)

Seed page: [https://en.wikipedia.org/wiki/List_of_most_popular_websites](https://en.wikipedia.org/wiki/List_of_most_popular_websites)


## webcrawl-8-4-2017-sample (Latest Sample) Info
This crawl obeys robots.txt.

This crawl was threaded. All but the first sample are multithreaded.
This means that Each websites is processed in its own thread.
Threading causes the websites to be processed faster, but the crawl will end sooner.

-------------------------------------
URL filter:
No urls containing the following were crawled:

webhp

ServiceLogin

mediawiki

twitter

apple

tango

commons

File:

Wikipedia:

'#'

'?'

icann

-------------------------------------

Reason the crawl ended: Too many threads were created (This is a common end reason for samples)

Seed page: [https://en.wikipedia.org/wiki/List_of_most_popular_websites](https://en.wikipedia.org/wiki/List_of_most_popular_websites)
